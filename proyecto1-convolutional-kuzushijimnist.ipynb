{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pedrobarrios/proyecto1-convolutional-kuzushijimnist?scriptVersionId=97746359\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# Cargando librerias a usar\nimport torch\nimport torchvision\nfrom torchvision import transforms, datasets\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport numpy as np\n\nimport helper\n\nprint(\"[INFO] Librerias cargadas\")","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:33:08.241401Z","iopub.execute_input":"2022-06-07T18:33:08.24221Z","iopub.status.idle":"2022-06-07T18:33:08.250231Z","shell.execute_reply.started":"2022-06-07T18:33:08.242167Z","shell.execute_reply":"2022-06-07T18:33:08.249306Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"[INFO] Librerias cargadas\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Carga de datos del dataset de Kuzushiji-MNIST de Anokas","metadata":{}},{"cell_type":"code","source":"#Funcion de apoyo para adaptar la forma del dataset\ndef resize(data):\n    data = data.reshape(data.shape[0], 1, data.shape[1], data.shape[2])\n    return data\n\nprint(\"[INFO] loading the KMNIST dataset...\")\n#Carga del dataset a arrays auxiliares\narr_train_img = np.load(\"../input/kuzushiji/kmnist-train-imgs.npz\")['arr_0']\narr_train_label = np.load(\"../input/kuzushiji/kmnist-train-labels.npz\")['arr_0']\narr_test_img = np.load(\"../input/kuzushiji/kmnist-test-imgs.npz\")['arr_0']\narr_test_label = np.load(\"../input/kuzushiji/kmnist-test-labels.npz\")['arr_0']\n\n#Pasandolos a Tensor de pytorch\ntrain_images = torch.Tensor(arr_train_img)/255\ntrain_labels = torch.Tensor(arr_train_label).type(torch.LongTensor)\ntest_images = torch.Tensor(arr_test_img)/255\ntest_labels = torch.Tensor(arr_test_label).type(torch.LongTensor)\n\n#Cambiando la forma del Tensor de las imagenes\ntrain_images,test_images = resize(train_images),resize(test_images)\n\nprint(\"[INFO] KMNIST dataset 50% loaded\")","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:33:08.354544Z","iopub.execute_input":"2022-06-07T18:33:08.35507Z","iopub.status.idle":"2022-06-07T18:33:09.13281Z","shell.execute_reply.started":"2022-06-07T18:33:08.355032Z","shell.execute_reply":"2022-06-07T18:33:09.131683Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"[INFO] loading the KMNIST dataset...\n[INFO] KMNIST dataset 50% loaded\n","output_type":"stream"}]},{"cell_type":"code","source":"#Verificando forma de la data importada y transformada\nprint(\"Imagenes\")\nprint(train_images.shape)\nprint(test_images.shape)\nprint(\"Labels\")\nprint(train_labels.shape)\nprint(test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:33:09.135353Z","iopub.execute_input":"2022-06-07T18:33:09.135871Z","iopub.status.idle":"2022-06-07T18:33:09.14287Z","shell.execute_reply.started":"2022-06-07T18:33:09.135821Z","shell.execute_reply":"2022-06-07T18:33:09.141708Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"Imagenes\ntorch.Size([60000, 1, 28, 28])\ntorch.Size([10000, 1, 28, 28])\nLabels\ntorch.Size([60000])\ntorch.Size([10000])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Clases, hiperparametros y Dataloader de pytorch estableciendo set de entrenamiento y set de pruebas","metadata":{}},{"cell_type":"code","source":"#HIPERPARAMETROS Y DEMAS\n\n# Creando las clases para los diferentes familias de caracteres a clasificar\nclasses = ('O', 'Ki', 'Su', 'Tsu'\n           , 'Na', 'Ha', 'Ma', 'Ya'\n           , 'Re', 'Wo')\n\n# Definimos el tama√±os de los batch, los Epoch y el rate de aprendizaje\nbatch_size = 32\nlearning_rate = 0.01\nepochs = 10\nsoftmax_classes = 10\n\n#Conversion de Tensor a Dataset de pytorch\ntrainset = torch.utils.data.TensorDataset(train_images,train_labels)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False)\n\ntestset = torch.utils.data.TensorDataset(test_images,test_labels)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n\nprint(\"[INFO] KMNIST dataset loaded\")","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:33:09.145095Z","iopub.execute_input":"2022-06-07T18:33:09.145916Z","iopub.status.idle":"2022-06-07T18:33:09.174155Z","shell.execute_reply.started":"2022-06-07T18:33:09.145868Z","shell.execute_reply":"2022-06-07T18:33:09.172911Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"[INFO] KMNIST dataset loaded\n","output_type":"stream"}]},{"cell_type":"markdown","source":"MODELOS DE REDES NEURONALES","metadata":{}},{"cell_type":"code","source":"# Arquitectura V1\nclass ConvNN(nn.Module):\n    def __init__(self, softmax_classes):\n        super(ConvNN, self).__init__()\n        self.conv_layer1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n        \n        self.fc1 = nn.Linear(784, 128)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(128, softmax_classes)\n    \n    # Progresses data across layers    \n    def forward(self, x):\n        out = self.conv_layer1(x)\n        out = self.max_pool1(out)\n                \n        out = torch.flatten(x,1)\n        \n        out = self.fc1(out)\n        out = self.relu1(out)\n        out = self.fc2(out)\n        out = F.log_softmax(out,dim=1)\n        return out\n    \nprint(\"[INFO] Arquitectura V1 utilizada\")","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:33:09.176703Z","iopub.execute_input":"2022-06-07T18:33:09.177651Z","iopub.status.idle":"2022-06-07T18:33:09.190019Z","shell.execute_reply.started":"2022-06-07T18:33:09.177572Z","shell.execute_reply":"2022-06-07T18:33:09.189069Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"[INFO] Arquitectura V1 utilizada\n","output_type":"stream"}]},{"cell_type":"code","source":"# Declaramos la red\nmodel = ConvNN(softmax_classes)\n\n# Definimos la metrica de la funcion de perdida\ncriterion = nn.CrossEntropyLoss()\n\n# Seleccionamos nuestro optimizador\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ntrain_loss=[]\ntran_acc=[]\n\nprint(\"[INFO] Modelo, funcion de perdida y optimizador declarados\")","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:33:09.191418Z","iopub.execute_input":"2022-06-07T18:33:09.192531Z","iopub.status.idle":"2022-06-07T18:33:09.210248Z","shell.execute_reply.started":"2022-06-07T18:33:09.192495Z","shell.execute_reply":"2022-06-07T18:33:09.209414Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"[INFO] Modelo, funcion de perdida y optimizador declarados\n","output_type":"stream"}]},{"cell_type":"code","source":"#Entrenamiento\nmodel.train()\nfor e in range(epochs):\n    totalTrainLoss  = 0\n    accuracy  = 0\n    for (images, labels) in trainloader:\n        \n        outputs = model(images)\n        \n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        \n        loss.backward()\n        \n        optimizer.step()\n\n        totalTrainLoss += loss.item()\n        _,trainCorrect = torch.max(nn.functional.softmax(outputs, dim=1), 1)\n        accuracy += (trainCorrect == labels).sum()\n        \n    else:\n        totalTrainLoss = totalTrainLoss/len(trainloader)\n        accuracy = (100 * accuracy.cpu().numpy()/len(train_images))\n        \n        print('Epoch:{} \\t Training Loss:{:.6f} \\t Accuracy:{}%'.format(\n            e, \n            totalTrainLoss,\n            accuracy\n        ))\n        \nprint(\"[INFO] Entrenamiento finalizado\")","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:33:09.211411Z","iopub.execute_input":"2022-06-07T18:33:09.21251Z","iopub.status.idle":"2022-06-07T18:37:30.921378Z","shell.execute_reply.started":"2022-06-07T18:33:09.212474Z","shell.execute_reply":"2022-06-07T18:37:30.920408Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Epoch:0 \t Training Loss:0.370298 \t Accuracy:88.49%\nEpoch:1 \t Training Loss:0.177100 \t Accuracy:94.595%\nEpoch:2 \t Training Loss:0.122732 \t Accuracy:96.30333333333333%\nEpoch:3 \t Training Loss:0.088016 \t Accuracy:97.36833333333334%\nEpoch:4 \t Training Loss:0.062867 \t Accuracy:98.245%\n[INFO] Entrenamiento finalizado\n","output_type":"stream"}]},{"cell_type":"code","source":"correctos = 0\ntodos = 0\nmodel.eval()\nwith torch.no_grad():\n    for images,labels in testloader:\n        # apagamos los gradiantes para acelerar el proceso\n        logps = model(images)\n        # salida del resultado de las redes con sus prob \n        ps = torch.exp(logps)\n        probab = list(ps.cpu().numpy()[0])\n        pred_label = probab.index(max(probab))\n        true_label = labels.numpy()\n        if(true_label == pred_label):correctos += 1\n        todos += 1\n\n\n\nprint('Images tested:{}\\t Accuracy:{}%'.format( \n        todos,\n        (correctos/todos)*100)\n    )\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:38:20.72557Z","iopub.execute_input":"2022-06-07T18:38:20.726159Z","iopub.status.idle":"2022-06-07T18:38:24.56682Z","shell.execute_reply.started":"2022-06-07T18:38:20.726125Z","shell.execute_reply":"2022-06-07T18:38:24.565703Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"Images tested:10000\t Accuracy:88.03999999999999%\n","output_type":"stream"}]},{"cell_type":"code","source":"def view_classify(img, ps):\n    ''' Function for viewing an image and it's predicted classes.\n    '''\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis('off')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    ax2.set_yticklabels(classes, size='small');\n    ax2.set_title('Class Probability')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]}]}