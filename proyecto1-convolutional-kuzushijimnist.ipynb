{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pedrobarrios/proyecto1-convolutional-kuzushijimnist?scriptVersionId=98285413\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# Cargando librerias a usar\nimport torch\nimport torchvision\nfrom torchvision import transforms, datasets\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport numpy as np\n\nimport helper\n\nprint(\"[INFO] Librerias cargadas\")","metadata":{"execution":{"iopub.status.busy":"2022-06-13T20:20:53.643038Z","iopub.execute_input":"2022-06-13T20:20:53.643513Z","iopub.status.idle":"2022-06-13T20:20:55.941169Z","shell.execute_reply.started":"2022-06-13T20:20:53.643419Z","shell.execute_reply":"2022-06-13T20:20:55.940187Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"[INFO] Librerias cargadas\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Carga de datos del dataset de Kuzushiji-MNIST de Anokas","metadata":{}},{"cell_type":"code","source":"#Funcion de apoyo para adaptar la forma del dataset\ndef resize(data):\n    data = data.reshape(data.shape[0], 1, data.shape[1], data.shape[2])\n    return data\n\nprint(\"[INFO] loading the KMNIST dataset...\")\n#Carga del dataset a arrays auxiliares\narr_train_img = np.load(\"../input/kuzushiji/kmnist-train-imgs.npz\")['arr_0']\narr_train_label = np.load(\"../input/kuzushiji/kmnist-train-labels.npz\")['arr_0']\narr_test_img = np.load(\"../input/kuzushiji/kmnist-test-imgs.npz\")['arr_0']\narr_test_label = np.load(\"../input/kuzushiji/kmnist-test-labels.npz\")['arr_0']\n\n#Pasandolos a Tensor de pytorch\ntrain_images = torch.Tensor(arr_train_img)/255\ntrain_labels = torch.Tensor(arr_train_label).type(torch.LongTensor)\ntest_images = torch.Tensor(arr_test_img)/255\ntest_labels = torch.Tensor(arr_test_label).type(torch.LongTensor)\n\n#Cambiando la forma del Tensor de las imagenes\ntrain_images,test_images = resize(train_images),resize(test_images)\n\nprint(\"[INFO] KMNIST dataset 50% loaded\")","metadata":{"execution":{"iopub.status.busy":"2022-06-13T20:20:58.228211Z","iopub.execute_input":"2022-06-13T20:20:58.228757Z","iopub.status.idle":"2022-06-13T20:20:59.392985Z","shell.execute_reply.started":"2022-06-13T20:20:58.228723Z","shell.execute_reply":"2022-06-13T20:20:59.392042Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[INFO] loading the KMNIST dataset...\n[INFO] KMNIST dataset 50% loaded\n","output_type":"stream"}]},{"cell_type":"code","source":"#Verificando forma de la data importada y transformada\nprint(\"Imagenes\")\nprint(train_images.shape)\nprint(test_images.shape)\nprint(\"Labels\")\nprint(train_labels.shape)\nprint(test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T17:06:30.747875Z","iopub.execute_input":"2022-06-12T17:06:30.748888Z","iopub.status.idle":"2022-06-12T17:06:30.754252Z","shell.execute_reply.started":"2022-06-12T17:06:30.74884Z","shell.execute_reply":"2022-06-12T17:06:30.753216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clases, hiperparametros y Dataloader de pytorch estableciendo set de entrenamiento y set de pruebas","metadata":{}},{"cell_type":"code","source":"#HIPERPARAMETROS Y DEMAS\n\n# Creando las clases para los diferentes familias de caracteres a clasificar\nclasses = ('O', 'Ki', 'Su', 'Tsu'\n           , 'Na', 'Ha', 'Ma', 'Ya'\n           , 'Re', 'Wo')\n\n# Definimos el tama√±os de los batch, los Epoch y el rate de aprendizaje\nbatch_size = 32\nlearning_rate = 0.01\nepochs = 20\nsoftmax_classes = 10\n\n#Conversion de Tensor a Dataset de pytorch\ntrainset = torch.utils.data.TensorDataset(train_images,train_labels)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False)\n\ntestset = torch.utils.data.TensorDataset(test_images,test_labels)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n\nprint(\"[INFO] KMNIST dataset loaded\")","metadata":{"execution":{"iopub.status.busy":"2022-06-13T20:21:03.391382Z","iopub.execute_input":"2022-06-13T20:21:03.391774Z","iopub.status.idle":"2022-06-13T20:21:03.399783Z","shell.execute_reply.started":"2022-06-13T20:21:03.39174Z","shell.execute_reply":"2022-06-13T20:21:03.398424Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[INFO] KMNIST dataset loaded\n","output_type":"stream"}]},{"cell_type":"markdown","source":"MODELOS DE REDES NEURONALES","metadata":{}},{"cell_type":"code","source":"# Arquitectura V1\nclass ConvNN(nn.Module):\n    def __init__(self, softmax_classes):\n        super(ConvNN, self).__init__()\n        self.conv_layer1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n        \n        self.fc1 = nn.Linear(5408, 128)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(128, softmax_classes)\n    \n    # Progresses data across layers    \n    def forward(self, x):\n        out = self.conv_layer1(x)\n        out = self.max_pool1(out)\n                \n        out = out.reshape(out.size(0), -1)\n        \n        out = self.fc1(out)\n        out = self.relu1(out)\n        out = self.fc2(out)\n        out = F.log_softmax(out,dim=1)\n        return out\n    \nprint(\"[INFO] Arquitectura V1 utilizada\")","metadata":{"execution":{"iopub.status.busy":"2022-06-12T18:19:53.168383Z","iopub.execute_input":"2022-06-12T18:19:53.16881Z","iopub.status.idle":"2022-06-12T18:19:53.178068Z","shell.execute_reply.started":"2022-06-12T18:19:53.168776Z","shell.execute_reply":"2022-06-12T18:19:53.176756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Arquitectura V2\nclass ConvNN(nn.Module):\n    def __init__(self, softmax_classes):\n        super(ConvNN, self).__init__()\n        self.conv_layer1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n        \n        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n        \n        self.fc1 = nn.Linear(1600, 128)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(128, softmax_classes)\n    \n    # Progresses data across layers    \n    def forward(self, x):\n        out = self.conv_layer1(x)\n        out = self.max_pool1(out)\n        \n        out = self.conv_layer2(out)\n        out = self.max_pool2(out)\n                \n        out = torch.flatten(out,1)\n        \n        out = self.fc1(out)\n        out = self.relu1(out)\n        out = self.fc2(out)\n        out = F.log_softmax(out,dim=1)\n        return out\n    \nprint(\"[INFO] Arquitectura V2 utilizada\")","metadata":{"execution":{"iopub.status.busy":"2022-06-13T20:21:39.091876Z","iopub.execute_input":"2022-06-13T20:21:39.092303Z","iopub.status.idle":"2022-06-13T20:21:39.10226Z","shell.execute_reply.started":"2022-06-13T20:21:39.092269Z","shell.execute_reply":"2022-06-13T20:21:39.100601Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[INFO] Arquitectura V2 utilizada\n","output_type":"stream"}]},{"cell_type":"code","source":"# Declaramos la red\nmodel = ConvNN(softmax_classes)\n\n# Definimos la metrica de la funcion de perdida\ncriterion = nn.CrossEntropyLoss()\n\n# Seleccionamos nuestro optimizador\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(\"[INFO] Modelo, funcion de perdida y optimizador declarados\")","metadata":{"execution":{"iopub.status.busy":"2022-06-13T20:21:41.46528Z","iopub.execute_input":"2022-06-13T20:21:41.465989Z","iopub.status.idle":"2022-06-13T20:21:41.474938Z","shell.execute_reply.started":"2022-06-13T20:21:41.46593Z","shell.execute_reply":"2022-06-13T20:21:41.474179Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[INFO] Modelo, funcion de perdida y optimizador declarados\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"[INFO] Iniciando entrenamiento del modelo\")\n#Entrenamiento\nmodel.train()\nfor e in range(epochs):\n    trainLoss  = 0\n    accuracy  = 0\n    for (images, labels) in trainloader:\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        trainLoss += loss.item()\n        _, predicted = torch.max(nn.functional.softmax(outputs, dim=1), 1)\n        accuracy += (predicted == labels).sum()\n        \n    else:\n        trainLoss = trainLoss/len(trainloader)\n        accuracy = 100 * accuracy.numpy()/len(train_images)\n        \n        print('Epoch:{} \\t Training Loss:{:.6f} \\t Training Acc:{:.2f}'.format(\n            e+1, \n            trainLoss,\n            accuracy\n        ))\n        \nprint(\"[INFO] Entrenamiento del modelo finalizado\")","metadata":{"execution":{"iopub.status.busy":"2022-06-13T21:11:47.154736Z","iopub.execute_input":"2022-06-13T21:11:47.15513Z","iopub.status.idle":"2022-06-13T21:12:49.421913Z","shell.execute_reply.started":"2022-06-13T21:11:47.155096Z","shell.execute_reply":"2022-06-13T21:12:49.42052Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"[INFO] Iniciando entrenamiento del modelo\nEpoch:1 \t Training Loss:0.009361 \t Training Acc:99.89\nEpoch:2 \t Training Loss:0.008195 \t Training Acc:99.90166666666667\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_54/3735378400.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"CODIGO PARA CALCULAR PRECISION CON EL SET DE PRUEBA","metadata":{}},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    accuracy = 0\n    test_loss = 0\n    acc_avg = []\n    testloss_avg = []\n    for images, labels in testloader:\n        output = model(images)\n        loss = criterion(output, labels)\n        test_loss = loss.item()/len(testloader)\n        _, predicted = torch.max(nn.functional.softmax(output, dim=1), 1)\n        accuracy += (predicted == labels).sum().item()\n        accuracyf = (100*accuracy)/labels.size(0)\n        acc_avg.append(accuracyf)\n        testloss_avg.append(test_loss)\n        accuracy,accuracyf = 0,0\n    print(f'Test Accuracy: {np.mean(acc_avg):.2f}%')\n    print(f'Test Loss: {np.mean(testloss_avg):.4f}%')\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-13T21:06:07.232931Z","iopub.execute_input":"2022-06-13T21:06:07.233313Z","iopub.status.idle":"2022-06-13T21:06:09.094109Z","shell.execute_reply.started":"2022-06-13T21:06:07.233274Z","shell.execute_reply":"2022-06-13T21:06:09.09312Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Test Accuracy: 93.20%\nTest Loss: 0.0010%\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef view_classify(img, ps):\n    ps = ps.data.numpy().squeeze()\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis('off')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    ax2.set_yticklabels(classes, size='small');\n    ax2.set_title('Class Probability')\n    ax2.set_xlim(0, 1.1)\n    plt.tight_layout()\n    \nmodel.eval()\nimages, labels = next(iter(testloader))\n\nwith torch.no_grad():\n    logps = model(images)\nps = torch.exp(logps[0])\n\nprobab = list(ps.numpy())\nprint(\"Clase predecida =\", classes[probab.index(max(probab))])\nprint(\"Clase correcta =\", classes[labels[0]])\n\nview_classify(img.resize_(1, 28, 28), ps)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T21:17:48.467209Z","iopub.execute_input":"2022-06-13T21:17:48.467608Z","iopub.status.idle":"2022-06-13T21:17:48.717066Z","shell.execute_reply.started":"2022-06-13T21:17:48.467574Z","shell.execute_reply":"2022-06-13T21:17:48.71621Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Clase predecida = Ya\nClase correcta = Ya\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x648 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}